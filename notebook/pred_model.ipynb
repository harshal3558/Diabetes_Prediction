{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a920ff",
   "metadata": {},
   "source": [
    "## Common Classification Models in Machine Learning\n",
    "\n",
    "Classification models are algorithms that categorize data points into predefined classes or groups. Below is a comprehensive list of widely used classification models, covering both classic and modern approaches:\n",
    "\n",
    "**Linear Models**\n",
    "- Logistic Regression\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "\n",
    "**Probabilistic Models**\n",
    "- Naive Bayes (Gaussian, Multinomial, Bernoulli)\n",
    "\n",
    "**Instance-Based Models**\n",
    "- k-Nearest Neighbors (KNN)\n",
    "\n",
    "**Tree-Based Models**\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Extra Trees (Extremely Randomized Trees)\n",
    "- Gradient Boosting Machines (GBM)\n",
    "- XGBoost\n",
    "- Bagging Classifier\n",
    "\n",
    "**Support Vector Machines**\n",
    "- Support Vector Machine (SVM), including various kernels (linear, polynomial, RBF, sigmoid)\n",
    "\n",
    "**Neural Networks**\n",
    "- Artificial Neural Networks (ANN)\n",
    "- Deep Neural Networks (DNN)\n",
    "- Convolutional Neural Networks (CNN) (for image classification)\n",
    "- Recurrent Neural Networks (RNN) (for sequence classification)\n",
    "- Ensemble of Neural Networks\n",
    "\n",
    "**Ensemble Methods**\n",
    "- Stacking and Blending (combining multiple models with a meta-classifier)\n",
    "- Bagging (Bootstrap Aggregating)\n",
    "- Boosting (AdaBoost, Gradient Boosting, XGBoost)\n",
    "\n",
    "**Other Models**\n",
    "- Quadratic Discriminant Analysis (QDA)\n",
    "- Cost-Sensitive Classifiers (for imbalanced data)\n",
    "- Multi-label and Multi-class adaptations of the above models\n",
    "\n",
    "## Specialized and Advanced Techniques\n",
    "\n",
    "- **Explainable AI (XAI) Techniques**: Not models themselves, but methods like SHAP, LIME, and counterfactual explanations are used to interpret complex classification models.\n",
    "- **Imbalanced Classification Approaches**: Cost-sensitive versions of standard models, sampling techniques (SMOTE, undersampling), and cluster-based oversampling.\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| Model Type              | Example Algorithms                                 |\n",
    "|-------------------------|---------------------------------------------------|\n",
    "| Linear                  | Logistic Regression, Linear Discriminant Analysis |\n",
    "| Probabilistic           | Naive Bayes                                       |\n",
    "| Instance-Based          | k-Nearest Neighbors                               |\n",
    "| Tree-Based              | Decision Tree, Random Forest, Gradient Boosting   |\n",
    "| Support Vector Machines | SVM (various kernels)                             |\n",
    "| Neural Networks         | ANN, DNN, CNN, RNN                                |\n",
    "| Ensemble Methods        | Bagging, Boosting, Stacking, Blending             |\n",
    "| Specialized             | Cost-sensitive, Multi-label, Multi-class versions |\n",
    "\n",
    "This list covers the most common and widely used classification models in machine learning, suitable for binary, multi-class, and multi-label tasks across various domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f04e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06eba33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\asd\\Desktop\\Diabetes_Prediction\\notebook\\data\\diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1401a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d95fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome',axis=1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b4b15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f728a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.75\n",
      "Logistic Regression Cross Validation score :[0.77272727 0.74675325 0.75974026 0.81699346 0.75163399]\n",
      "Mean of Cross Validation Score: 0.7695696460402341\n",
      "------------------------------------------------------------\n",
      "Logistic Regression Cross Validation Scaled score :[0.77272727 0.74675325 0.75324675 0.81699346 0.76470588]\n",
      "Mean of Scaled Cross Validation Score: 0.7708853238265002\n",
      "============================================================\n",
      "SVM Accuracy: 0.73\n",
      "SVM Cross Validation score :[0.74675325 0.73376623 0.77272727 0.79084967 0.75163399]\n",
      "Mean of Cross Validation Score: 0.7591460826754943\n",
      "------------------------------------------------------------\n",
      "SVM Cross Validation Scaled score :[0.76623377 0.75324675 0.74675325 0.81045752 0.77777778]\n",
      "Mean of Scaled Cross Validation Score: 0.7708938120702827\n",
      "============================================================\n",
      "KNN Accuracy: 0.69\n",
      "KNN Cross Validation score :[0.72727273 0.72727273 0.7012987  0.75816993 0.70588235]\n",
      "Mean of Cross Validation Score: 0.723979288685171\n",
      "------------------------------------------------------------\n",
      "KNN Cross Validation Scaled score :[0.72077922 0.73376623 0.71428571 0.77124183 0.7254902 ]\n",
      "Mean of Scaled Cross Validation Score: 0.733112638994992\n",
      "============================================================\n",
      "Random Forest Accuracy: 0.74\n",
      "Random Forest Cross Validation score :[0.75974026 0.72727273 0.74675325 0.83006536 0.75163399]\n",
      "Mean of Cross Validation Score: 0.7630931160342925\n",
      "------------------------------------------------------------\n",
      "Random Forest Cross Validation Scaled score :[0.75974026 0.72727273 0.75324675 0.83006536 0.77124183]\n",
      "Mean of Scaled Cross Validation Score: 0.7683133859604447\n",
      "============================================================\n",
      "AdaBoost Accuracy: 0.78\n",
      "AdaBoost Cross Validation score :[0.74675325 0.75974026 0.75974026 0.81045752 0.75816993]\n",
      "Mean of Cross Validation Score: 0.7669722434428318\n",
      "------------------------------------------------------------\n",
      "AdaBoost Cross Validation Scaled score :[0.74675325 0.75974026 0.75974026 0.81045752 0.75816993]\n",
      "Mean of Scaled Cross Validation Score: 0.7669722434428318\n",
      "============================================================\n",
      "Gradient Boosting Accuracy: 0.75\n",
      "Gradient Boosting Cross Validation score :[0.79220779 0.71428571 0.72077922 0.81045752 0.75163399]\n",
      "Mean of Cross Validation Score: 0.7578728461081402\n",
      "------------------------------------------------------------\n",
      "Gradient Boosting Cross Validation Scaled score :[0.77922078 0.72077922 0.72077922 0.81045752 0.75163399]\n",
      "Mean of Scaled Cross Validation Score: 0.756574144809439\n",
      "============================================================\n",
      "XGBoost Accuracy: 0.71\n",
      "XGBoost Cross Validation score :[0.73376623 0.71428571 0.72077922 0.80392157 0.73202614]\n",
      "Mean of Cross Validation Score: 0.7409557762498938\n",
      "------------------------------------------------------------\n",
      "XGBoost Cross Validation Scaled score :[0.73376623 0.71428571 0.72077922 0.80392157 0.73202614]\n",
      "Mean of Scaled Cross Validation Score: 0.7409557762498938\n",
      "============================================================\n",
      "MLP (Neural Network) Accuracy: 0.75\n",
      "MLP (Neural Network) Cross Validation score :[0.66233766 0.65584416 0.7012987  0.69281046 0.65359477]\n",
      "Mean of Cross Validation Score: 0.6731771496477379\n",
      "------------------------------------------------------------\n",
      "MLP (Neural Network) Cross Validation Scaled score :[0.74675325 0.74025974 0.77922078 0.79084967 0.77124183]\n",
      "Mean of Scaled Cross Validation Score: 0.7656650539003479\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'MLP (Neural Network)': MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    score = model.score(X_test_scaled, y_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cross_score = cross_val_score(model, X, y, cv=5)\n",
    "    print(f\"{name} Accuracy: {score:.2f}\")\n",
    "    print(f\"{name} Cross Validation score :{cross_score}\")\n",
    "    print(f\"Mean of Cross Validation Score: {cross_score.mean()}\")\n",
    "    print(\"--\"*30)\n",
    "\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    cross_score1 = cross_val_score(model, X_scaled, y, cv=5)\n",
    "    print(f\"{name} Cross Validation Scaled score :{cross_score1}\")\n",
    "    print(f\"Mean of Scaled Cross Validation Score: {cross_score1.mean()}\")\n",
    "    print(\"==\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d22430c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      ", Accuracy_Score: 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81        99\n",
      "           1       0.65      0.67      0.66        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.74      0.73       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n",
      "Model: SVM\n",
      ", Accuracy_Score: 0.7337662337662337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80        99\n",
      "           1       0.65      0.56      0.60        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.70      0.70       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "Model: KNN\n",
      ", Accuracy_Score: 0.6948051948051948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77        99\n",
      "           1       0.58      0.51      0.54        55\n",
      "\n",
      "    accuracy                           0.69       154\n",
      "   macro avg       0.66      0.65      0.66       154\n",
      "weighted avg       0.69      0.69      0.69       154\n",
      "\n",
      "Model: Random Forest\n",
      ", Accuracy_Score: 0.7532467532467533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        99\n",
      "           1       0.65      0.65      0.65        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.73      0.73       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "Model: AdaBoost\n",
      ", Accuracy_Score: 0.7792207792207793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82        99\n",
      "           1       0.68      0.73      0.70        55\n",
      "\n",
      "    accuracy                           0.78       154\n",
      "   macro avg       0.76      0.77      0.76       154\n",
      "weighted avg       0.78      0.78      0.78       154\n",
      "\n",
      "Model: Gradient Boosting\n",
      ", Accuracy_Score: 0.7467532467532467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        99\n",
      "           1       0.64      0.67      0.65        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.73      0.73       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n",
      "Model: XGBoost\n",
      ", Accuracy_Score: 0.7077922077922078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76        99\n",
      "           1       0.58      0.65      0.62        55\n",
      "\n",
      "    accuracy                           0.71       154\n",
      "   macro avg       0.69      0.70      0.69       154\n",
      "weighted avg       0.72      0.71      0.71       154\n",
      "\n",
      "Model: MLP (Neural Network)\n",
      ", Accuracy_Score: 0.7337662337662337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80        99\n",
      "           1       0.63      0.60      0.62        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.70      0.71       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model: {model_name}\\n, Accuracy_Score: {accuracy}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c8d82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
